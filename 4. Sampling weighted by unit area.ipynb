{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area and accuracy estimation for sampling with inclusion probabilities weighted by pixel area, from Tyukavina et al. (in review) \"Options for global sampling of geographic data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read strata info table with columns:\n",
    "#\"Stratum\" - stratum ID, 1 - nstrata;\n",
    "#\"Area_km2\" - stratum area in km2 or any other area units, needs to be consistend with pixel size area units in data table;\n",
    "#\"Sample_size\" - number of units sampled from each stratum;\n",
    "#(for sampling without replacement only)\"SumPixareaSq\" - \n",
    "#sum of squared areas of all (not only sampled) units (pixels/polygons) within each stratum\n",
    "strata = pd.read_csv('4.strata_info.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_680e2268_2de7_11ec_800c_d0946613b163\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Stratum</th>        <th class=\"col_heading level0 col1\" >Area_km2</th>        <th class=\"col_heading level0 col2\" >Sample_size</th>        <th class=\"col_heading level0 col3\" >SumPixareaSq</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row0_col1\" class=\"data row0 col1\" >595255.012800</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row0_col2\" class=\"data row0 col2\" >134</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row0_col3\" class=\"data row0 col3\" >449.495424</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row1_col1\" class=\"data row1 col1\" >332992.902600</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row1_col2\" class=\"data row1 col2\" >100</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row1_col3\" class=\"data row1 col3\" >146.067021</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row2_col1\" class=\"data row2 col1\" >946369.335100</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row2_col2\" class=\"data row2 col2\" >213</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row2_col3\" class=\"data row2 col3\" >700.634849</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row3_col1\" class=\"data row3 col1\" >486272.535600</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row3_col2\" class=\"data row3 col2\" >109</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row3_col3\" class=\"data row3 col3\" >280.287541</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row4_col1\" class=\"data row4 col1\" >669855.474600</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row4_col2\" class=\"data row4 col2\" >150</td>\n",
       "                        <td id=\"T_680e2268_2de7_11ec_800c_d0946613b163row4_col3\" class=\"data row4 col3\" >494.909501</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19345559908>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strata.head().style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read sample interpretation table with columns:\n",
    "#\"Stratum\" - stratum ID, 1 - nstrata;\n",
    "#\"Pixarea\" - area of each sampled pixel/polygon in units consistent with strata area from the sample table (e.g. km2)\n",
    "#\"Map\"(for accuracy assessment only) - proportion of target class from the map (0-1) for each sample unit;\n",
    "#\"Reference\" - proportion of target class from reference sample classification for each sample unit;\n",
    "#allowed values are from -1 to 1 for area estimation, and from 0 to 1 for map accuracy assessment.\n",
    "#(optional)\"RefType\" - type labels, if the are of target class needs to be estimated separately for multiple sub-types\n",
    "#(optional)\"Correct\" - proportion of sample unit (0-1), which is correctly mapped. \n",
    "#This column is necessary for maps with more than two classes. \n",
    "#For map with two classes it is computed in the function \"estimate_OA_two_classes\" directly from \"Map\" and \"Reference\" columns\n",
    "\n",
    "data = pd.read_csv('4.Sample_data.txt', sep ='\\t')\n",
    "\n",
    "#Merge data table with sample info table\n",
    "data = data.merge(strata)\n",
    "data = data.rename(columns = {'Area_km2':'Ah', 'Sample_size':'nh', 'Pixarea':'ai'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_76578d1c_2de7_11ec_a570_d0946613b163\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Stratum</th>        <th class=\"col_heading level0 col1\" >ai</th>        <th class=\"col_heading level0 col2\" >Map</th>        <th class=\"col_heading level0 col3\" >Reference</th>        <th class=\"col_heading level0 col4\" >RefType</th>        <th class=\"col_heading level0 col5\" >Correct</th>        <th class=\"col_heading level0 col6\" >Ah</th>        <th class=\"col_heading level0 col7\" >nh</th>        <th class=\"col_heading level0 col8\" >SumPixareaSq</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row0_col0\" class=\"data row0 col0\" >10</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row0_col1\" class=\"data row0 col1\" >0.000638</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row0_col2\" class=\"data row0 col2\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row0_col3\" class=\"data row0 col3\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row0_col4\" class=\"data row0 col4\" >Type1</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row0_col5\" class=\"data row0 col5\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row0_col6\" class=\"data row0 col6\" >161635.388000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row0_col7\" class=\"data row0 col7\" >100</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row0_col8\" class=\"data row0 col8\" >112.372396</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row1_col0\" class=\"data row1 col0\" >10</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row1_col1\" class=\"data row1 col1\" >0.000626</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row1_col3\" class=\"data row1 col3\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row1_col4\" class=\"data row1 col4\" >Type1</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row1_col5\" class=\"data row1 col5\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row1_col6\" class=\"data row1 col6\" >161635.388000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row1_col7\" class=\"data row1 col7\" >100</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row1_col8\" class=\"data row1 col8\" >112.372396</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row2_col0\" class=\"data row2 col0\" >10</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row2_col1\" class=\"data row2 col1\" >0.000769</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row2_col3\" class=\"data row2 col3\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row2_col4\" class=\"data row2 col4\" >Type1</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row2_col5\" class=\"data row2 col5\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row2_col6\" class=\"data row2 col6\" >161635.388000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row2_col7\" class=\"data row2 col7\" >100</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row2_col8\" class=\"data row2 col8\" >112.372396</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row3_col0\" class=\"data row3 col0\" >10</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row3_col1\" class=\"data row3 col1\" >0.000670</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row3_col4\" class=\"data row3 col4\" >Type1</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row3_col5\" class=\"data row3 col5\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row3_col6\" class=\"data row3 col6\" >161635.388000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row3_col7\" class=\"data row3 col7\" >100</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row3_col8\" class=\"data row3 col8\" >112.372396</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row4_col0\" class=\"data row4 col0\" >10</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row4_col1\" class=\"data row4 col1\" >0.000649</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row4_col4\" class=\"data row4 col4\" >Type1</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row4_col5\" class=\"data row4 col5\" >1.000000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row4_col6\" class=\"data row4 col6\" >161635.388000</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row4_col7\" class=\"data row4 col7\" >100</td>\n",
       "                        <td id=\"T_76578d1c_2de7_11ec_a570_d0946613b163row4_col8\" class=\"data row4 col8\" >112.372396</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1934660d1d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head().style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to estimate class area and its standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_area(df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate target class area from sample refernce values \n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling both with and without replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification;\n",
    "    Reference data column could be defined as values in range from -1 to 1 to compute net change area of a target class,\n",
    "    in this case negative proportions mean net loss, and positive proportions - net gain)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    ~~~\n",
    "    Returns estimated target class area in units of Ah, \n",
    "    negative area in net change computations means overall net loss of a target class\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 22 and 25\n",
    "    \"\"\"\n",
    "    #Create a copy of column \"Stratum\" and a new column \"ForArea\", \n",
    "    #computed as wi= yi×Ah (equation 22), where yi == Reference (reference proportion of a target class, estimated for each sample unit)\n",
    "    df1 = pd.concat([df['Stratum'], pd.Series((df['Reference'] * df['Ah']) , name = 'ForArea')], axis = 1)\n",
    "    \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    # Equation 25, compute area of target class in each stratum\n",
    "    #Mean area of target class for each stratum\n",
    "    areastrat = ByStratum.ForArea.sum() / ByStratum.ForArea.count()\n",
    "    #Sum over all strata\n",
    "    area = areastrat.sum()\n",
    "\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_area_SE(df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate standard error (SE) of the target class area from sample refernce values \n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling both with and without replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification;\n",
    "    Reference data column could be defined as values in range from -1 to 1 to compute net change area of a target class,\n",
    "    in this case negative proportions mean net loss, and positive proportions - net gain)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    ~~~\n",
    "    Returns estimated SE of the target class area in in units of Ah,\n",
    "    SE is always a positive number, even if the estimated target class area is negative\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 22 and 27\n",
    "    \"\"\"\n",
    "    #Create a copy of column \"Stratum\" and a new column \"ForVar\", \n",
    "    #computed as wi= yi×Ah (equation 22), where yi == Reference (reference proportion of a target class, estimated for each sample unit)\n",
    "    df1 = pd.concat([df['Stratum'],pd.Series(df['Reference'] * df['Ah'], name = 'ForVar')],axis = 1)\n",
    "    \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 27\n",
    "    #Compute variance for each stratum\n",
    "    StrataVar = ByStratum.ForVar.var(ddof=1) / ByStratum.ForVar.count() \n",
    "    #Sum strata-specific variances\n",
    "    StrataVarSum = StrataVar.sum()\n",
    "    #Compute SE of the estimated class area from a sum of strata variances\n",
    "    SE = np.sqrt(StrataVarSum)\n",
    "    \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223903.8326854417"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimate target class area\n",
    "estimate_area(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31611.122385173083"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimate standard error of the target class area\n",
    "estimate_area_SE(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_786f05da_2de7_11ec_84ed_d0946613b163\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Estimate</th>        <th class=\"col_heading level0 col1\" >area, km²</th>        <th class=\"col_heading level0 col2\" >area SE, km²</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row0_col0\" class=\"data row0 col0\" >Type3</td>\n",
       "                        <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row0_col1\" class=\"data row0 col1\" >383052.9482</td>\n",
       "                        <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row0_col2\" class=\"data row0 col2\" >32929.1133</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row1_col0\" class=\"data row1 col0\" >Type2</td>\n",
       "                        <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row1_col1\" class=\"data row1 col1\" >608160.8876</td>\n",
       "                        <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row1_col2\" class=\"data row1 col2\" >38476.2797</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row2_col0\" class=\"data row2 col0\" >Type0</td>\n",
       "                        <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row2_col1\" class=\"data row2 col1\" >0.0000</td>\n",
       "                        <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row3_col0\" class=\"data row3 col0\" >Type1</td>\n",
       "                        <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row3_col1\" class=\"data row3 col1\" >232689.9969</td>\n",
       "                        <td id=\"T_786f05da_2de7_11ec_84ed_d0946613b163row3_col2\" class=\"data row3 col2\" >27599.9173</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1934660d978>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimate target class are for each unique type from the column RefType\n",
    "\n",
    "functions = [estimate_area, estimate_area_SE]\n",
    "names = ['area, km²','area SE, km²']\n",
    "results = pd.DataFrame()\n",
    "datacopy = pd.DataFrame()\n",
    "\n",
    "for classtype in data['RefType'].unique():\n",
    "    datacopy = data.copy()\n",
    "    #A new reference column, where reference values are set to zero if class type is different from the current class type\n",
    "    datacopy['Reference']=np.where(datacopy['RefType'] == classtype, datacopy['Reference'], 0)\n",
    "    \n",
    "    values = {}\n",
    "    values = {nm:[fn(datacopy)] for fn, nm in zip(functions,names)}\n",
    "    values[\"Estimate\"] = classtype\n",
    "    values_pd = pd.DataFrame(values).set_index(\"Estimate\")\n",
    "    results = pd.concat([values_pd, results])\n",
    "\n",
    "results = results.reset_index()\n",
    "\n",
    "results.style.hide_index().format({name: '{:.4f}' for name in names})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to estimate overall map area and its standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_OA_two_classes (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate overall accuracy of the map that has two classes (target class vs. no target class)\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling both with and without replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    ans the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    ~~~\n",
    "    Returns estimated overall accuracy of the map expressed as percent of the total study area\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 22, 25 and 26\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Stratum\",\"Ah\" and a new column \"Correct, \n",
    "    #where the proportion of the sample unit that is correctly classified (as either of map classes) is computed as: \n",
    "    #min (\"Map\", \"Reference\") + min (1-\"Map\", 1-\"Reference\"), and multiplied by stratum area (equation 22)\n",
    "    df1 = pd.concat([df['Stratum'], df['Ah'],\n",
    "                     pd.Series((np.minimum(df['Map'],df['Reference']) + np.minimum((1 - df['Map']),(1 - df['Reference']))) * df['Ah'],name = 'Correct')], axis = 1)\n",
    "                     \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 25\n",
    "    #compute correctly classified area in each stratum\n",
    "    CorrectlyClassified = ByStratum.Correct.sum() / ByStratum.Correct.count()\n",
    "    #sum correctly classified areas accross all strata\n",
    "    CorrectlyClassifiedSum = CorrectlyClassified.sum()\n",
    "    \n",
    "    #Equation 26\n",
    "    #Derive an Overall Accuracy metric by dividing the sum of correctly classified areas by the total study area\n",
    "    OA = (CorrectlyClassifiedSum / ((ByStratum.Ah.median()).sum())) * 100\n",
    "\n",
    "    return OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.08916693742641"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_OA_two_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_OA_multiple_classes (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate overall accuracy of the map that has multiple classes\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling both with and without replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    ans the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Correct\" - proportion of sample unit (0-1), which is correctly mapped\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    ~~~\n",
    "    Returns estimated overall accuracy of the map expressed as percent of the total study area\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 22, 25 and 26\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Stratum\",\"Ah\" and a new column \"Correct\", \n",
    "    #where the proportion of the sample unit that is correctly classified is multiplied by stratum area (equation 22)\n",
    "    df1 = pd.concat([df['Stratum'], df['Ah'],\n",
    "                     pd.Series(df['Correct'] * df['Ah'],name = 'Correct')], axis = 1)\n",
    "                     \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 25\n",
    "    #compute correctly classified area in each stratum\n",
    "    CorrectlyClassified = ByStratum.Correct.sum() / ByStratum.Correct.count()\n",
    "    #sum correctly classified areas accross all strata\n",
    "    CorrectlyClassifiedSum = CorrectlyClassified.sum()\n",
    "    \n",
    "    #Equation 26\n",
    "    #Derive an overall accuracy metric by dividing the sum of correctly classified areas by the total study area\n",
    "    OA = (CorrectlyClassifiedSum / ((ByStratum.Ah.median()).sum())) * 100\n",
    "\n",
    "    return OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.08916693742641"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_OA_multiple_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_SE_OA_two_classes (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error of overall accuracy of the map that has two classes \n",
    "    (target class vs. no target class) for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling both with and without replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    ans the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    ~~~\n",
    "    Returns estimated standard error of the overall accuracy of the map expressed as percent of the total study area\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 22, 27 and 28\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Stratum\",\"Ah\" and a new column \"Correct, \n",
    "    #where the proportion of the sample unit that is correctly classified (as either of map classes) is computed as: \n",
    "    #min (\"Map\", \"Reference\") + min (1-\"Map\", 1-\"Reference\"), and multiplied by stratum area (equation 22)\n",
    "    df1 = pd.concat([df['Stratum'], df['Ah'],\n",
    "                     pd.Series((np.minimum(df['Map'],df['Reference']) + np.minimum((1 - df['Map']),(1 - df['Reference']))) * df['Ah'],name = 'Correct')], axis = 1)\n",
    "                     \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 27\n",
    "    #compute variance for each stratum\n",
    "    StrataVar = ByStratum.Correct.var(ddof=1) / ByStratum.Correct.count()\n",
    "    #sum strata-specific variances\n",
    "    StrataVarSum = StrataVar.sum()\n",
    "    \n",
    "    #Compute SE of the estimated class area from a sum of strata variances divided by the total study area\n",
    "    SE = (np.sqrt(StrataVarSum) / ((ByStratum.Ah.median()).sum())) * 100\n",
    "    \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7080373503205022"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_SE_OA_two_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_SE_OA_multiple_classes (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error of overall accuracy of the map that has multiple classes\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling both with and without replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    ans the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Correct\" - proportion of sample unit (0-1), which is correctly mapped\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    ~~~\n",
    "    Returns estimated standard error of the overall accuracy of the map expressed as percent of the total study area\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 22, 27 and 28\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Stratum\",\"Ah\" and a new column \"Correct\", \n",
    "    #where the proportion of the sample unit that is correctly classified is multiplied by stratum area (equation 22)\n",
    "    df1 = pd.concat([df['Stratum'], df['Ah'],\n",
    "                     pd.Series(df['Correct'] * df['Ah'],name = 'Correct')], axis = 1)\n",
    "                     \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 27\n",
    "    #compute variance for each stratum\n",
    "    StrataVar = ByStratum.Correct.var(ddof=1) / ByStratum.Correct.count()\n",
    "    #sum strata-specific variances\n",
    "    StrataVarSum = StrataVar.sum()\n",
    "    \n",
    "    #Compute SE of the estimated class area from a sum of strata variances divided by the total study area\n",
    "    SE = (np.sqrt(StrataVarSum) / ((ByStratum.Ah.median()).sum())) * 100\n",
    "    \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7080373503205022"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_SE_OA_multiple_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_UA (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate user's accuracy of target class\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling both with and without replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"nh\" (number of sample pixels in stratum h)\n",
    "    \"ai\" (area of sampled pixel in the same units as Ah)\n",
    "    ~~~\n",
    "    Returns estimated user's accuracy of target class expressed as percentage\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 21, 23, 29, 30, 31\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"nh\",\"Ah\",\"ai\" and new columns computed as (equation 23):\n",
    "    \n",
    "    #\"Correct\", the proportion of the sample unit that is correctly classified as target class:\n",
    "    # min (\"Map\", \"Reference\"), and multiplied by the sample unit area; \n",
    "    #\"Mapped\": \"Map\", multiplied by the sample unit area.\n",
    "    df1 = pd.concat([df['nh'],df['Ah'],df['ai'], pd.Series((np.minimum(df['Map'],df['Reference']) * df['ai']) , name = 'Correct'),\n",
    "                    pd.Series((df['Map'] * df['ai']) , name = 'Mapped')],axis = 1)\n",
    "    \n",
    "    #Equation 21 Compute inclusion probability for each sampled unit\n",
    "    df1['PIi'] = df1['nh'] * df1['ai'] / df1['Ah']\n",
    "    \n",
    "    #Equation 30\n",
    "    West = (df1.Correct / df1.PIi).sum()\n",
    "    #Equation 31\n",
    "    Zest = (df1.Mapped / df1.PIi).sum()\n",
    "    \n",
    "    #Equation 29\n",
    "    UA = West / Zest * 100\n",
    "\n",
    "    return UA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.6910655161679"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_UA(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_PA (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate producer's accuracy of target class\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling both with and without replacement.\n",
    "    ~~~ \n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"nh\" (number of sample pixels in stratum h)\n",
    "    \"ai\" (area of sampled pixel in the same units as Ah)\n",
    "    ~~~\n",
    "    Returns estimated producer's accuracy of target class expressed as percentage\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 21, 23, 29-31\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"nh\", \"Ah\",\"ai\" and new columns computed as (equation 23):\n",
    "    #\"Correct\", the proportion of the sample unit that is correctly classified as target class:\n",
    "    # min (\"Map\", \"Reference\"), and multiplied by the sample unit area;\n",
    "    #\"Ref\": \"Reference\", multiplied by the sample unit area.\n",
    "    df1 = pd.concat([df['nh'],df['Ah'],df['ai'], pd.Series((np.minimum(df['Map'],df['Reference']) * df['ai']), name = 'Correct'),\n",
    "                    pd.Series((df['Reference'] * df['ai']) , name = 'Ref')],axis = 1)\n",
    "    \n",
    "    #Equation 21 Compute inclusion probability for each sampled pixel\n",
    "    df1['PIi'] = df1['nh'] * df1['ai'] / df1['Ah']\n",
    "    \n",
    "    #Equation 30\n",
    "    West = (df1.Correct / df1.PIi).sum()\n",
    "    #Equation 31\n",
    "    Zest = (df1.Ref / df1.PIi).sum()\n",
    "    \n",
    "    #Equation 29\n",
    "    PA = West / Zest * 100\n",
    "\n",
    "    return PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.62678633355188"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_PA(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_UA_SE_with_replacement(df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error (SE) of user's accuracy of target class\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling with replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"nh\" (number of sample pixels in stratum h)\n",
    "    \"ai\" (area of sampled pixel in the same units as Ah)\n",
    "    ~~~\n",
    "    Returns estimated SE of user's accuracy of target class expressed as percentage\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 21, 23, 29-32\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"nh\", \"Ah\",\"ai\" and new columns computed as (equation 23):\n",
    "    \n",
    "    #\"Correct\", the proportion of the sample unit that is correctly classified as target class:\n",
    "    # min (\"Map\", \"Reference\"), and multiplied by the sample unit area; \n",
    "    #\"Mapped\": \"Map\", multiplied by the sample unit area.\n",
    "    df1 = pd.concat([df['nh'],df['Ah'],df['ai'], pd.Series((np.minimum(df['Map'],df['Reference']) * df['ai']) , name = 'Correct'),\n",
    "                    pd.Series((df['Map'] * df['ai']) , name = 'Mapped')],axis = 1)\n",
    "    \n",
    "    #Equation 21 Compute inclusion probability for each sampled unit\n",
    "    df1['PIi'] = df1['nh'] * df1['ai'] / df1['Ah']\n",
    "    \n",
    "    #Equation 30\n",
    "    West = (df1.Correct / df1.PIi).sum()\n",
    "    #Equation 31\n",
    "    Zest = (df1.Mapped / df1.PIi).sum()\n",
    "    #Equation 29\n",
    "    UA = West / Zest\n",
    "    \n",
    "    # Equation 32\n",
    "    var_i = (1 - df1['PIi']) * (df1['Correct'] - UA * df1['Mapped']) * (df1['Correct'] - UA * df1['Mapped']) / (df1['PIi'] * df1['PIi'])\n",
    "    var = np.sum(var_i) / Zest**2\n",
    "    \n",
    "    SE = np.sqrt(var) * 100\n",
    "     \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8753281165637898"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_UA_SE_with_replacement(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_UA_SE_without_replacement (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error (SE) of user's accuracy of target class\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling without replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"nh\" (number of sample pixels in stratum h)\n",
    "    \"ai\" (area of sampled pixel in the same units as Ah)\n",
    "    \"SumPixareaSq\" (sum of squared areas of all (not only sampled) units (pixels/polygons) within each stratum)\n",
    "    ~~~\n",
    "    Returns estimated SE of user's accuracy of target class expressed as percentage\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 21, 23, 29-31, 33-35\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"nh\", \"Ah\",\"ai\", \"SumPixareaSq\" and new columns computed as (equation 23):\n",
    "    \n",
    "    #\"Correct\", the proportion of the sample unit that is correctly classified as target class:\n",
    "    # min (\"Map\", \"Reference\"), and multiplied by the sample unit area; \n",
    "    #\"Mapped\": \"Map\", multiplied by the sample unit area.\n",
    "    df1 = pd.concat([df['Stratum'],df['nh'],df['Ah'],df['ai'],df['SumPixareaSq'], pd.Series((np.minimum(df['Map'],df['Reference']) * df['ai']) , name = 'Correct'),\n",
    "                    pd.Series((df['Map'] * df['ai']) , name = 'Mapped')],axis = 1)\n",
    "    \n",
    "    #Equation 21 Compute inclusion probability for each sampled unit\n",
    "    df1['PIi'] = df1['nh'] * df1['ai'] / df1['Ah']\n",
    "    \n",
    "    #Equation 30\n",
    "    West = (df1.Correct / df1.PIi).sum()\n",
    "    #Equation 31\n",
    "    Zest = (df1.Mapped / df1.PIi).sum()\n",
    "    #Equation 29\n",
    "    UA = West / Zest\n",
    "    \n",
    "    #Equation 35\n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    K = (ByStratum.SumPixareaSq.median() * ByStratum.nh.median()) / (ByStratum.Ah.median())**2\n",
    "    \n",
    "    n = len(df1)\n",
    "    \n",
    "    PIi = np.broadcast_to(df1.PIi, (n, n))\n",
    "    PIj = PIi.T\n",
    "    Stratumh = np.broadcast_to(df1.Stratum, (n, n))\n",
    "    nh = np.broadcast_to(df1.nh, (n, n)) \n",
    "    Kh = np.broadcast_to(K[df1['Stratum']], (n, n))\n",
    "    PIiPIj = PIi * PIj\n",
    "    samestratum = (Stratumh == Stratumh.T).astype(int) #to check whether pixels i and j are in the same stratum\n",
    "    \n",
    "    # Equation 34\n",
    "    PIij_num = (nh - 1) * PIiPIj\n",
    "    PIij_denom = nh - PIi - PIj + Kh\n",
    "    PIij = PIij_num / PIij_denom\n",
    "    \n",
    "    # Equation 33\n",
    "    var_i = (df1['Correct'] - UA * df1['Mapped']) / df1['PIi']\n",
    "    var_ij = (1 - PIiPIj / PIij) * np.tensordot(var_i, var_i, axes=0) * samestratum\n",
    "    var_ij[np.diag_indices_from(var_ij)] = (1 - df1['PIi']) * var_i ** 2\n",
    "    var = np.sum(var_ij) / Zest ** 2\n",
    "    \n",
    "    SE = np.sqrt(var)*100\n",
    "     \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8257850328247602"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_UA_SE_without_replacement(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_PA_SE_with_replacement(df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error (SE) of producer's accuracy of target class\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling with replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"nh\" (number of sample pixels in stratum h)\n",
    "    \"ai\" (area of sampled pixel in the same units as Ah)\n",
    "    ~~~\n",
    "    Returns estimated SE of producer's accuracy of target class expressed as percentage\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 21, 23, 29-32\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"nh\", \"Ah\",\"ai\" and new columns computed as (equation 23):\n",
    "    #\"Correct\", the proportion of the sample unit that is correctly classified as target class:\n",
    "    # min (\"Map\", \"Reference\"), and multiplied by the sample unit area;\n",
    "    #\"Ref\": \"Reference\", multiplied by the sample unit area.\n",
    "    df1 = pd.concat([df['nh'],df['Ah'],df['ai'], pd.Series((np.minimum(df['Map'],df['Reference']) * df['ai']), name = 'Correct'),\n",
    "                    pd.Series((df['Reference'] * df['ai']) , name = 'Ref')],axis = 1)\n",
    "    \n",
    "    #Equation 21 Compute inclusion probability for each sampled unit\n",
    "    df1['PIi'] = df1['nh'] * df1['ai'] / df1['Ah']\n",
    "    \n",
    "    #Equation 30\n",
    "    West = (df1.Correct / df1.PIi).sum()\n",
    "    #Equation 31\n",
    "    Zest = (df1.Ref / df1.PIi).sum()\n",
    "    #Equation 29\n",
    "    PA = West / Zest\n",
    "    \n",
    "    # Equation 32\n",
    "    var_i = (1 - df1['PIi']) * (df1['Correct'] - PA * df1['Ref'])*(df1['Correct'] - PA * df1['Ref']) / (df1['PIi'] * df1['PIi'])\n",
    "    var = np.sum(var_i) / Zest**2\n",
    "    \n",
    "    SE = np.sqrt(var)*100\n",
    "     \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.432911087835729"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_PA_SE_with_replacement(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_PA_SE_without_replacement (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error (SE) of producer's accuracy of target class\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling without replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"nh\" (number of sample pixels in stratum h)\n",
    "    \"ai\" (area of sampled pixel in the same units as Ah)\n",
    "    \"SumPixareaSq\" (sum of squared areas of all (not only sampled) units (pixels/polygons) within each stratum)\n",
    "    ~~~\n",
    "    Returns estimated SE of producer's accuracy of target class expressed as percentage\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 21, 23, 29-31, 33-35\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"nh\", \"Ah\",\"ai\", \"SumPixareaSq\" and new columns computed as (equation 23):\n",
    "    \n",
    "    #\"Correct\", the proportion of the sample unit that is correctly classified as target class:\n",
    "    # min (\"Map\", \"Reference\"), and multiplied by the sample unit area; \n",
    "    #\"Ref\": \"Reference\", multiplied by the sample unit area.\n",
    "    df1 = pd.concat([df['Stratum'],df['nh'],df['Ah'],df['ai'],df['SumPixareaSq'], pd.Series((np.minimum(df['Map'],df['Reference']) * df['ai']) , name = 'Correct'),\n",
    "                    pd.Series((df['Reference'] * df['ai']) , name = 'Ref')],axis = 1)\n",
    "    \n",
    "    #Equation 21 Compute inclusion probability for each sampled unit\n",
    "    df1['PIi'] = df1['nh'] * df1['ai'] / df1['Ah']\n",
    "    \n",
    "    #Equation 30\n",
    "    West = (df1.Correct / df1.PIi).sum()\n",
    "    #Equation 31\n",
    "    Zest = (df1.Ref / df1.PIi).sum()\n",
    "    #Equation 29\n",
    "    PA = West / Zest\n",
    "    \n",
    "    #Equation 35\n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    K = (ByStratum.SumPixareaSq.median() * ByStratum.nh.median()) /(ByStratum.Ah.median())**2\n",
    "    \n",
    "    n = len(df1)\n",
    "    \n",
    "    PIi = np.broadcast_to(df1.PIi, (n, n))\n",
    "    PIj = PIi.T\n",
    "    Stratumh = np.broadcast_to(df1.Stratum, (n, n))\n",
    "    nh = np.broadcast_to(df1.nh, (n, n)) \n",
    "    Kh = np.broadcast_to(K[df1['Stratum']], (n, n))\n",
    "    PIiPIj = PIi * PIj\n",
    "    samestratum = (Stratumh == Stratumh.T).astype(int) #to check whether pixels i and j are in the same stratum\n",
    "    \n",
    "    # Equation 34\n",
    "    PIij_num = (nh - 1) * PIiPIj\n",
    "    PIij_denom = nh - PIi - PIj + Kh\n",
    "    PIij = PIij_num / PIij_denom\n",
    "    \n",
    "    # Equation 33\n",
    "    var_i = (df1['Correct'] - PA * df1['Ref']) / df1['PIi']\n",
    "    var_ij = (1 - PIiPIj / PIij) * np.tensordot(var_i, var_i, axes=0) * samestratum\n",
    "    var_ij[np.diag_indices_from(var_ij)] = (1 - df1['PIi']) * var_i ** 2\n",
    "    var = np.sum(var_ij) / Zest**2\n",
    "    \n",
    "    SE = np.sqrt(var) * 100\n",
    "     \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3788942976134728"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_PA_SE_without_replacement(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to estimate % of class1 from class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_class_percent (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate percent of class1 from class2, both estimated from the sample\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling both with and without replacement.\n",
    "    ~~~ \n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Class1\" (0-1 - proportion of the sample pixel/polygon identified as class 1 (percentage numerator))\n",
    "    \"Class2\" (0-1 - proportion of the sample pixel/polygon identified as class 1 (percentage denumerator))\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"nh\" (number of sample pixels in stratum h)\n",
    "    \"ai\" (area of sampled pixel in the same units as Ah)\n",
    "    ~~~\n",
    "    Returns estimated percent of class1 from the area of class2\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 21, 22, 29-31\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"nh\", \"Ah\",\"ai\" and new columns \"Class1\" and \"Class2\" computed as (equation 23):\n",
    "    #original columns \"Class1\" and \"Class2\" multiplied by the sample unit area;\n",
    "    df1 = pd.concat([df['nh'],df['Ah'],df['ai'], pd.Series((df['Class1'] * df['ai']), name = 'Class1'),\n",
    "                    pd.Series((df['Class2'] * df['ai']) , name = 'Class2')],axis = 1)\n",
    "    \n",
    "    #Equation 21 Compute inclusion probability for each sampled pixel\n",
    "    df1['PIi'] = df1['nh'] * df1['ai'] / df1['Ah']\n",
    "    \n",
    "    #Equation 30\n",
    "    West = (df1.Class1 / df1.PIi).sum()\n",
    "    #Equation 31\n",
    "    Zest = (df1.Class2 / df1.PIi).sum()\n",
    "    \n",
    "    #Equation 29\n",
    "    PERC = West / Zest * 100\n",
    "\n",
    "    return PERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_class_percent_SE_with_replacement(df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error (SE) of percent of class1 from class2, both estimated from the sample\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling with replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Class1\" (0-1 - proportion of the sample pixel/polygon identified as class 1 (percentage numerator))\n",
    "    \"Class2\" (0-1 - proportion of the sample pixel/polygon identified as class 1 (percentage denumerator))\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"nh\" (number of sample pixels in stratum h)\n",
    "    \"ai\" (area of sampled pixel in the same units as Ah)\n",
    "    ~~~\n",
    "    Returns estimated SE of percent of class1 from class2\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 21, 23, 29-32\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"nh\", \"Ah\",\"ai\" and new columns \"Class1\" and \"Class2\" computed as (equation 23):\n",
    "    #original columns \"Class1\" and \"Class2\" multiplied by the sample unit area;\n",
    "    df1 = pd.concat([df['nh'],df['Ah'],df['ai'], pd.Series((df['Class1'] * df['ai']), name = 'Class1'),\n",
    "                    pd.Series((df['Class2'] * df['ai']) , name = 'Class2')],axis = 1)\n",
    "    \n",
    "    #Equation 21 Compute inclusion probability for each sampled pixel\n",
    "    df1['PIi'] = df1['nh'] * df1['ai'] / df1['Ah']\n",
    "    \n",
    "    #Equation 30\n",
    "    West = (df1.Class1 / df1.PIi).sum()\n",
    "    #Equation 31\n",
    "    Zest = (df1.Class2 / df1.PIi).sum()\n",
    "    #Equation 29\n",
    "    PERC = West / Zest\n",
    "    \n",
    "    # Equation 32\n",
    "    var_i = (1 - df1['PIi']) * (df1['Class1'] - PERC * df1['Class2']) * (df1['Class1'] - PERC * df1['Class2']) / (df1['PIi'] * df1['PIi'])\n",
    "    var = np.sum(var_i) / Zest**2\n",
    "    \n",
    "    SE = np.sqrt(var) * 100\n",
    "     \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_class_percent_SE_without_replacement (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error (SE) of percent of class1 from class2, both estimated from the sample\n",
    "    for sampling of units with inclusion probability weighted by the unit area.\n",
    "    Valid for sampling without replacement.\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Class1\" (0-1 - proportion of the sample pixel/polygon identified as class 1 (percentage numerator))\n",
    "    \"Class2\" (0-1 - proportion of the sample pixel/polygon identified as class 1 (percentage denumerator))\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"nh\" (number of sample pixels in stratum h)\n",
    "    \"ai\" (area of sampled pixel in the same units as Ah)\n",
    "    \"SumPixareaSq\" (sum of squared areas of all (not only sampled) units (pixels/polygons) within each stratum)\n",
    "    ~~~\n",
    "    Returns estimated SE of percent of class1 from class2\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 21, 23, 29-31, 33-35\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Stratum\", nh\", \"Ah\",\"ai\", \"SumPixareaSq\" and new columns \"Class1\" and \"Class2\" computed as (equation 23):\n",
    "    #original columns \"Class1\" and \"Class2\" multiplied by the sample unit area;\n",
    "    df1 = pd.concat([df['Stratum'],df['nh'],df['Ah'],df['ai'],df['SumPixareaSq'], pd.Series((df['Class1'] * df['ai']), name = 'Class1'),\n",
    "                    pd.Series((df['Class2'] * df['ai']) , name = 'Class2')],axis = 1)\n",
    "    \n",
    "    #Equation 21 Compute inclusion probability for each sampled pixel\n",
    "    df1['PIi'] = df1['nh'] * df1['ai'] / df1['Ah']\n",
    "    \n",
    "    #Equation 30\n",
    "    West = (df1.Class1 / df1.PIi).sum()\n",
    "    #Equation 31\n",
    "    Zest = (df1.Class2 / df1.PIi).sum()\n",
    "    #Equation 29\n",
    "    PERC = West / Zest\n",
    "    \n",
    "    #Equation 35\n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    K = (ByStratum.SumPixareaSq.median() * ByStratum.nh.median()) / (ByStratum.Ah.median())**2\n",
    "    \n",
    "    n = len(df1)\n",
    "    \n",
    "    PIi = np.broadcast_to(df1.PIi, (n, n))\n",
    "    PIj = PIi.T\n",
    "    Stratumh = np.broadcast_to(df1.Stratum, (n, n))\n",
    "    nh = np.broadcast_to(df1.nh, (n, n)) \n",
    "    Kh = np.broadcast_to(K[df1['Stratum']], (n, n))\n",
    "    PIiPIj = PIi * PIj\n",
    "    samestratum = (Stratumh == Stratumh.T).astype(int) #to check whether pixels i and j are in the same stratum\n",
    "    \n",
    "    # Equation 34\n",
    "    PIij_num = (nh - 1) * PIiPIj\n",
    "    PIij_denom = nh - PIi - PIj + Kh\n",
    "    PIij = PIij_num / PIij_denom\n",
    "    \n",
    "    # Equation 33\n",
    "    var_i = (df1['Class1'] - PERC * df1['Class2']) / df1['PIi']\n",
    "    var_ij = (1 - PIiPIj / PIij) * np.tensordot(var_i, var_i, axes=0) * samestratum\n",
    "    var_ij[np.diag_indices_from(var_ij)] = (1 - df1['PIi']) * var_i ** 2\n",
    "    var = np.sum(var_ij) / Zest**2\n",
    "    \n",
    "    SE = np.sqrt(var) * 100\n",
    "     \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_83f20d12_2de7_11ec_9931_d0946613b163\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Estimate</th>        <th class=\"col_heading level0 col1\" >% from target class</th>        <th class=\"col_heading level0 col2\" >SE with replacement</th>        <th class=\"col_heading level0 col3\" >SE without replacement</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row0_col0\" class=\"data row0 col0\" >Type3</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row0_col1\" class=\"data row0 col1\" >31.30</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row0_col2\" class=\"data row0 col2\" >2.61</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row0_col3\" class=\"data row0 col3\" >2.61</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row1_col0\" class=\"data row1 col0\" >Type2</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row1_col1\" class=\"data row1 col1\" >49.69</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row1_col2\" class=\"data row1 col2\" >2.80</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row1_col3\" class=\"data row1 col3\" >2.81</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row2_col0\" class=\"data row2 col0\" >Type0</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row2_col1\" class=\"data row2 col1\" >0.00</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row2_col3\" class=\"data row2 col3\" >0.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row3_col0\" class=\"data row3 col0\" >Type1</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row3_col1\" class=\"data row3 col1\" >19.01</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row3_col2\" class=\"data row3 col2\" >2.19</td>\n",
       "                        <td id=\"T_83f20d12_2de7_11ec_9931_d0946613b163row3_col3\" class=\"data row3 col3\" >2.20</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19346708eb8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of use: estimate % of Types 0-3 from the overall area of the target class (Reference>0).\n",
    "\n",
    "functions = [estimate_class_percent, estimate_class_percent_SE_with_replacement, estimate_class_percent_SE_without_replacement]\n",
    "names = ['% from target class','SE with replacement', 'SE without replacement']\n",
    "results = pd.DataFrame()\n",
    "datacopy = pd.DataFrame()\n",
    "\n",
    "for classtype in data['RefType'].unique():\n",
    "    datacopy = data.copy()\n",
    "    #A new Class1 column, where reference values are set to zero if class type is different from the current class type\n",
    "    datacopy['Class1'] = np.where(datacopy['RefType'] == classtype, datacopy['Reference'], 0)\n",
    "    \n",
    "    #Set Class2 equal to Reference (total area of target class)\n",
    "    datacopy['Class2'] = datacopy['Reference']\n",
    "    \n",
    "    \n",
    "    values = {}\n",
    "    values = {nm:[fn(datacopy)] for fn, nm in zip(functions,names)}\n",
    "    values[\"Estimate\"] = classtype\n",
    "    values_pd = pd.DataFrame(values).set_index(\"Estimate\")\n",
    "    results = pd.concat([values_pd, results])\n",
    "\n",
    "results = results.reset_index()\n",
    "\n",
    "results.style.hide_index().format({name: '{:.2f}' for name in names})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
