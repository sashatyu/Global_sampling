{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area and accuracy estimation for sampling of units with esual area, strata weighted by number of units, from Tyukavina et al. (in review) \"Options for global sampling of geographic data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read strata info table with columns:\n",
    "#\"Stratum\" - stratum ID, 1 - nstrata;\n",
    "#\"Area_km2\" - stratum area in km2 or any other area units, needs to be consistend with pixel size area units in data table;\n",
    "#\"Count\" - total number of units (pixels, polygons) in each stratum\n",
    "strata = pd.read_csv('2-3.strata_info.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Stratum</th>        <th class=\"col_heading level0 col1\" >Area_km2</th>        <th class=\"col_heading level0 col2\" >Count</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row0_col1\" class=\"data row0 col1\" >595255.012800</td>\n",
       "                        <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row0_col2\" class=\"data row0 col2\" >788889906</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "                        <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row1_col1\" class=\"data row1 col1\" >332992.902600</td>\n",
       "                        <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row1_col2\" class=\"data row1 col2\" >781490883</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "                        <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row2_col1\" class=\"data row2 col1\" >946369.335100</td>\n",
       "                        <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row2_col2\" class=\"data row2 col2\" >1280971777</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "                        <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row3_col1\" class=\"data row3 col1\" >486272.535600</td>\n",
       "                        <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row3_col2\" class=\"data row3 col2\" >859622001</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "                        <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row4_col1\" class=\"data row4 col1\" >669855.474600</td>\n",
       "                        <td id=\"T_212fe80c_2de7_11ec_89c2_d0946613b163row4_col2\" class=\"data row4 col2\" >909836775</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bff92089e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strata.head().style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read sample interpretation table with columns:\n",
    "#\"Stratum\" - stratum ID, 1 - nstrata;\n",
    "#\"Map\"(for accuracy assessment only) - proportion of target class from the map (0-1) for each sample unit;\n",
    "#\"Reference\" - proportion of target class from reference sample classification for each sample unit;\n",
    "#allowed values are from -1 to 1 for area estimation, and from 0 to 1 for map accuracy assessment.\n",
    "#(optional)\"RefType\" - type labels, if the are of target class needs to be estimated separately for multiple sub-types\n",
    "#(optional)\"Correct\" - proportion of sample unit (0-1), which is correctly mapped. \n",
    "#This column is necessary for maps with more than two classes. \n",
    "#For map with two classes it is computed in the function \"estimate_OA_two_classes\" directly from \"Map\" and \"Reference\" columns\n",
    "\n",
    "data = pd.read_csv('2-3.Sample_data.txt', sep ='\\t')\n",
    "\n",
    "#Merge data table with sample info table\n",
    "data = data.merge(strata)\n",
    "data = data.rename(columns = {'Area_km2':'Ah', 'Count':'Nh'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_21384b94_2de7_11ec_a01b_d0946613b163\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Stratum</th>        <th class=\"col_heading level0 col1\" >Map</th>        <th class=\"col_heading level0 col2\" >Reference</th>        <th class=\"col_heading level0 col3\" >RefType</th>        <th class=\"col_heading level0 col4\" >Correct</th>        <th class=\"col_heading level0 col5\" >Ah</th>        <th class=\"col_heading level0 col6\" >Nh</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row0_col0\" class=\"data row0 col0\" >10</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row0_col1\" class=\"data row0 col1\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row0_col2\" class=\"data row0 col2\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row0_col3\" class=\"data row0 col3\" >Type1</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row0_col4\" class=\"data row0 col4\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row0_col5\" class=\"data row0 col5\" >161635.388000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row0_col6\" class=\"data row0 col6\" >234157691</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row1_col0\" class=\"data row1 col0\" >10</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row1_col3\" class=\"data row1 col3\" >Type1</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row1_col4\" class=\"data row1 col4\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row1_col5\" class=\"data row1 col5\" >161635.388000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row1_col6\" class=\"data row1 col6\" >234157691</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row2_col0\" class=\"data row2 col0\" >10</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row2_col3\" class=\"data row2 col3\" >Type1</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row2_col4\" class=\"data row2 col4\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row2_col5\" class=\"data row2 col5\" >161635.388000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row2_col6\" class=\"data row2 col6\" >234157691</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row3_col0\" class=\"data row3 col0\" >10</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row3_col1\" class=\"data row3 col1\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row3_col3\" class=\"data row3 col3\" >Type1</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row3_col4\" class=\"data row3 col4\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row3_col5\" class=\"data row3 col5\" >161635.388000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row3_col6\" class=\"data row3 col6\" >234157691</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row4_col0\" class=\"data row4 col0\" >10</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row4_col3\" class=\"data row4 col3\" >Type1</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row4_col5\" class=\"data row4 col5\" >161635.388000</td>\n",
       "                        <td id=\"T_21384b94_2de7_11ec_a01b_d0946613b163row4_col6\" class=\"data row4 col6\" >234157691</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bffa2cee80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head().style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to estimate class area and its standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_area(df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate target class area from sample refernce values \n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification;\n",
    "    Reference data column could be defined as values in range from -1 to 1 to compute net change area of a target class,\n",
    "    in this case negative proportions mean net loss, and positive proportions - net gain)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated target class area in units of Ah, \n",
    "    negative area in net change computations means overall net loss of a target class\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 3 and 4\n",
    "    \"\"\"\n",
    "    #Group input dataset by stratum\n",
    "    ByStratum = df.groupby(by = ['Stratum'])\n",
    "    \n",
    "    # Equation 3\n",
    "    Nh =  ByStratum.Nh.median()\n",
    "    N = Nh.sum()\n",
    "    proportion = Nh * ByStratum.Reference.mean() / N\n",
    "    \n",
    "    #Sum over all strata and multiply by total area (Equation 4)\n",
    "    Atot = ByStratum.Ah.median().sum()\n",
    "    area = proportion.sum() * Atot\n",
    "\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_area_SE(df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate target class area from sample refernce values \n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification;\n",
    "    Reference data column could be defined as values in range from -1 to 1 to compute net change area of a target class,\n",
    "    in this case negative proportions mean net loss, and positive proportions - net gain)\n",
    "    \"Ah\" (stratum area, km²<or any other area unit>)\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated SE of the target class area in in units of Ah,\n",
    "    SE is always a positive number, even if the estimated target class area is negative\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 6 and 7\n",
    "    \"\"\"\n",
    "    \n",
    "    ByStratum = df.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 6\n",
    "    Nh = ByStratum.Nh.median()\n",
    "    nh = ByStratum.Reference.count()\n",
    "    Forstrata = ByStratum.Reference.var(ddof=1) / nh\n",
    "    StrataVar = Forstrata * (1 - nh / Nh) * Nh**2\n",
    "    N = Nh.sum()\n",
    "    StrataVarSum = StrataVar.sum() / N / N\n",
    "    #Equation 7\n",
    "    Atot = ByStratum.Ah.median().sum()\n",
    "    SE = np.sqrt(StrataVarSum) * Atot\n",
    "    \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1564753.3915654607"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimate target class area\n",
    "estimate_area(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38348.157702564364"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimate standard error of the target class area\n",
    "estimate_area_SE(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Estimate</th>        <th class=\"col_heading level0 col1\" >area, km²</th>        <th class=\"col_heading level0 col2\" >area SE, km²</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row0_col0\" class=\"data row0 col0\" >Type3</td>\n",
       "                        <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row0_col1\" class=\"data row0 col1\" >499503.8249</td>\n",
       "                        <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row0_col2\" class=\"data row0 col2\" >45035.4896</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row1_col0\" class=\"data row1 col0\" >Type2</td>\n",
       "                        <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row1_col1\" class=\"data row1 col1\" >769153.3741</td>\n",
       "                        <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row1_col2\" class=\"data row1 col2\" >50682.0920</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row2_col0\" class=\"data row2 col0\" >Type0</td>\n",
       "                        <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row2_col1\" class=\"data row2 col1\" >0.0000</td>\n",
       "                        <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row3_col0\" class=\"data row3 col0\" >Type1</td>\n",
       "                        <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row3_col1\" class=\"data row3 col1\" >296096.1926</td>\n",
       "                        <td id=\"T_2935d948_2de7_11ec_9ee0_d0946613b163row3_col2\" class=\"data row3 col2\" >37117.3059</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bffa2cee10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimate target class are for each unique type from the column RefType\n",
    "\n",
    "functions = [estimate_area, estimate_area_SE]\n",
    "names = ['area, km²','area SE, km²']\n",
    "results = pd.DataFrame()\n",
    "datacopy = pd.DataFrame()\n",
    "\n",
    "for classtype in data['RefType'].unique():\n",
    "    datacopy = data.copy()\n",
    "    #A new reference column, where reference values are set to zero if class type is different from the current class type\n",
    "    datacopy['Reference'] = np.where(datacopy['RefType'] == classtype, datacopy['Reference'], 0)\n",
    "    \n",
    "    values = {}\n",
    "    values = {nm:[fn(datacopy)] for fn, nm in zip(functions,names)}\n",
    "    values[\"Estimate\"] = classtype\n",
    "    values_pd = pd.DataFrame(values).set_index(\"Estimate\")\n",
    "    results = pd.concat([values_pd, results])\n",
    "\n",
    "results = results.reset_index()\n",
    "\n",
    "results.style.hide_index().format({name: '{:.4f}' for name in names})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to estimate overall map area and its standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_OA_two_classes (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate overall accuracy of the map that has two classes (target class vs. no target class)\n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    ans the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated overall accuracy of the map expressed as percent of the total study area\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 3 and 5\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Stratum\",\"Nh\" and a new column \"Correct, \n",
    "    #where the proportion of the sample unit that is correctly classified (as either of map classes) is computed as: \n",
    "    #min (\"Map\", \"Reference\") + min (1-\"Map\", 1-\"Reference\")\n",
    "    df1 = pd.concat([df['Stratum'], df['Nh'],\n",
    "                     pd.Series((np.minimum(df['Map'],df['Reference'])+ np.minimum((1-df['Map']),(1-df['Reference']))),name = 'Correct')], axis = 1)\n",
    "                     \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 3\n",
    "    proportion = ByStratum.Nh.median() * ByStratum.Correct.mean() / (ByStratum.Nh.median()).sum()\n",
    "    \n",
    "    #Equation 5\n",
    "    OA = proportion.sum() * 100\n",
    "\n",
    "    return OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.41793783017692"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_OA_two_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_OA_multiple_classes (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate overall accuracy of the map that has multiple classes\n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    ans the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Correct\" - proportion of sample unit (0-1), which is correctly mapped\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated overall accuracy of the map expressed as percent of the total study area\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 3 and 5\n",
    "    \"\"\"               \n",
    "    ByStratum = df.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 3\n",
    "    proportion = ByStratum.Nh.median() * ByStratum.Correct.mean() / (ByStratum.Nh.median()).sum()\n",
    "    \n",
    "    #Equation 5\n",
    "    OA = proportion.sum() * 100\n",
    "\n",
    "    return OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.41793783017692"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_OA_multiple_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_SE_OA_two_classes (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error of overall accuracy of the map that has two classes \n",
    "    (target class vs. no target class) for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    ans the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated standard error of the overall accuracy of the map expressed as percent of the total study area\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 6 and 7\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Stratum\",\"Nh\" and a new column \"Correct, \n",
    "    #where the proportion of the sample unit that is correctly classified (as either of map classes) is computed as: \n",
    "    #min (\"Map\", \"Reference\") + min (1-\"Map\", 1-\"Reference\")\n",
    "    df1 = pd.concat([df['Stratum'], df['Nh'],\n",
    "                     pd.Series((np.minimum(df['Map'],df['Reference']) + np.minimum((1 - df['Map']),(1 - df['Reference']))),name = 'Correct')], axis = 1)\n",
    "                     \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 6\n",
    "    Nh = ByStratum.Nh.median()\n",
    "    nh = ByStratum.Correct.count()\n",
    "    Forstrata = ByStratum.Correct.var(ddof=1) / nh\n",
    "    StrataVar = Forstrata * (1 - nh / Nh) * Nh**2\n",
    "    N = Nh.sum()\n",
    "    StrataVarSum = StrataVar.sum() / N / N\n",
    "    #Equation 7\n",
    "    SE = np.sqrt(StrataVarSum) * 100\n",
    "    \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858039217405162"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_SE_OA_two_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_SE_OA_multiple_classes (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error of overall accuracy of the map that has multiple classes\n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    ans the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Correct\" - proportion of sample unit (0-1), which is correctly mapped\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated standard error of the overall accuracy of the map expressed as percent of the total study area\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 6 and 7\n",
    "    \"\"\"\n",
    "    ByStratum = df.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 6\n",
    "    Nh = ByStratum.Nh.median()\n",
    "    nh = ByStratum.Correct.count()\n",
    "    Forstrata = ByStratum.Correct.var(ddof=1) / nh\n",
    "    StrataVar = Forstrata * (1 - nh / Nh) * Nh**2\n",
    "    N = Nh.sum()\n",
    "    StrataVarSum = StrataVar.sum() / N / N\n",
    "    #Equation 7\n",
    "    SE = np.sqrt(StrataVarSum) * 100\n",
    "    \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858039217405162"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_SE_OA_multiple_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_UA (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate user's accuracy of target class\n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated user's accuracy of target class expressed as percentage\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equation 9\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Nh\", \"Map\" and a new column computed as:\n",
    "    #\"Correct\", the proportion of the sample unit that is correctly classified as target class: min (\"Map\", \"Reference\")\n",
    "    df1 = pd.concat([df['Stratum'],df['Nh'],df['Map'], \n",
    "                     pd.Series((np.minimum(df['Map'],df['Reference'])) , name = 'Correct')],axis = 1)\n",
    "    \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 9\n",
    "    Nh = ByStratum.Nh.median()\n",
    "    Yest = (Nh * ByStratum.Correct.mean()).sum()\n",
    "    Xest = (Nh * ByStratum.Map.mean()).sum()\n",
    "    UA = Yest / Xest * 100\n",
    "\n",
    "    return UA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.59206405937368"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_UA(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_PA (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate producer's accuracy of target class\n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~ \n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated producer's accuracy of target class expressed as percentage\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equation 9\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Nh\", \"Reference\" and a new column computed as:\n",
    "    #\"Correct\", the proportion of the sample unit that is correctly classified as target class: min (\"Map\", \"Reference\")\n",
    "    df1 = pd.concat([df['Stratum'],df['Nh'],df['Reference'], \n",
    "                     pd.Series((np.minimum(df['Map'],df['Reference'])) , name = 'Correct')],axis = 1)\n",
    "    \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 9\n",
    "    Nh = ByStratum.Nh.median()\n",
    "    Yest = (Nh * ByStratum.Correct.mean()).sum()\n",
    "    Xest = (Nh * ByStratum.Reference.mean()).sum()\n",
    "    PA = Yest / Xest * 100\n",
    "\n",
    "    return PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.76568315876409"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_PA(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_UA_SE(df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error (SE) of user's accuracy of target class\n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated SE of user's accuracy of target class expressed as percentage\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 9-11\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Ah\",\"Stratum\", \"Map\" and new columns computed as:\n",
    "    #\"Correct\", the proportion of the sample unit that is correctly classified as target class: min (\"Map\", \"Reference\");\n",
    "    df1 = pd.concat([df['Nh'],df['Stratum'], df['Map'],\n",
    "                     pd.Series((np.minimum(df['Map'],df['Reference'])) , name = 'Correct')],axis = 1)\n",
    "    \n",
    "    df1['XY'] = df1['Map'] * df1['Correct']\n",
    "    \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 11\n",
    "    Nh = ByStratum.Nh.median()\n",
    "    Xest = (Nh * ByStratum.Map.mean()).sum()\n",
    "    \n",
    "    #Equation 9\n",
    "    Yest = (Nh * ByStratum.Correct.mean()).sum()\n",
    "    R = Yest / Xest\n",
    "\n",
    "    # Equation 10\n",
    "    nh = ByStratum.Correct.count()\n",
    "    meanyh = ByStratum.Correct.mean()\n",
    "    meanxh = ByStratum.Map.mean()\n",
    "    vary = ByStratum.Correct.var(ddof=1)\n",
    "    varx = ByStratum.Map.var(ddof=1)\n",
    "    covarxy = (ByStratum.XY.sum() - nh * meanyh * meanxh) / (nh - 1)\n",
    "    StrataVar = Nh**2 * (1 - nh / Nh) * (vary + R**2 * varx - 2 * R * covarxy) / nh\n",
    "    StrataVarSum = StrataVar.sum() / Xest / Xest\n",
    "    SE = np.sqrt(StrataVarSum) * 100\n",
    "     \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9330022817204517"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_UA_SE(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_PA_SE(df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error (SE) of producer's accuracy of target class\n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Map\" (0-1 - proportion of the sample pixel/polygon identified as target class in the map)\n",
    "    \"Reference\" (0-1 - proportion of the sample pixel/polygon identified as target class in reference classification)\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated SE of producer's accuracy of target class expressed as percentage\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 9-11\n",
    "    \"\"\"\n",
    "    #Create a copy of columns \"Ah\",\"Stratum\", \"Reference\" and new columns computed as:\n",
    "    #\"Correct\", the proportion of the sample unit that is correctly classified as target class: min (\"Map\", \"Reference\");\n",
    "    df1 = pd.concat([df['Nh'],df['Stratum'], df['Reference'],\n",
    "                     pd.Series((np.minimum(df['Map'],df['Reference'])) , name = 'Correct')],axis = 1)\n",
    "    \n",
    "    df1['XY'] = df1['Reference'] * df1['Correct']\n",
    "    \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 11\n",
    "    Nh = ByStratum.Nh.median()\n",
    "    Xest = (Nh * ByStratum.Reference.mean()).sum()\n",
    "    \n",
    "    #Equation 9\n",
    "    Yest = (Nh * ByStratum.Correct.mean()).sum()\n",
    "    R = Yest / Xest\n",
    "\n",
    "    # Equation 10\n",
    "    nh = ByStratum.Correct.count()\n",
    "    meanyh = ByStratum.Correct.mean()\n",
    "    meanxh = ByStratum.Reference.mean()\n",
    "    vary = ByStratum.Correct.var(ddof=1)\n",
    "    varx = ByStratum.Reference.var(ddof=1)\n",
    "    covarxy = (ByStratum.XY.sum() - nh * meanyh * meanxh) / (nh - 1)\n",
    "    StrataVar = Nh**2 * (1 - nh / Nh) * (vary + R**2 * varx - 2 * R * covarxy) / nh\n",
    "    StrataVarSum = StrataVar.sum() / Xest / Xest\n",
    "    SE = np.sqrt(StrataVarSum) * 100\n",
    "     \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9336026822407393"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_PA_SE(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to estimate % of class1 from class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_class_percent (df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate percent of class1 from class2, both estimated from the sample\n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~ \n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Class1\" (0-1 - proportion of the sample pixel/polygon identified as class 1 (percentage numerator))\n",
    "    \"Class2\" (0-1 - proportion of the sample pixel/polygon identified as class 1 (percentage denumerator))\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated percent of class1 from the area of class2\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equation 9\n",
    "    \"\"\"\n",
    "    ByStratum = df.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 9\n",
    "    Nh = ByStratum.Nh.median()\n",
    "    Yest = (Nh * ByStratum.Class1.mean()).sum()\n",
    "    Xest = (Nh * ByStratum.Class2.mean()).sum()\n",
    "    PERC = Yest / Xest * 100\n",
    "\n",
    "    return PERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_class_percent_SE(df: pd.DataFrame) -> float:\n",
    "    \"\"\" \n",
    "    Function to estimate the standard error (SE) of percent of class1 from class2, both estimated from the sample\n",
    "    for sampling of units (pixels/polygons) with equal area.\n",
    "    Strata weighted by their respective unit counts (Nh).\n",
    "    ~~~\n",
    "    Input dataframe with number of lines equal the number of sample pixels/polygons,\n",
    "    and the following columns:\n",
    "    \"Stratum\" (strata IDs 1 - nstrata)\n",
    "    \"Class1\" (0-1 - proportion of the sample pixel/polygon identified as class 1 (percentage numerator))\n",
    "    \"Class2\" (0-1 - proportion of the sample pixel/polygon identified as class 1 (percentage denumerator))\n",
    "    \"Nh\" (number of units in each stratum h)\n",
    "    ~~~\n",
    "    Returns estimated SE of percent of class1 from class2\n",
    "    ~~~\n",
    "    From Tyukavina et al. (in review) \"Options for global sampling of geographic data\"\n",
    "    Appendix, equations 9-11\n",
    "    \"\"\"\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    df1['XY'] = df1['Class1'] * df1['Class2']\n",
    "    \n",
    "    ByStratum = df1.groupby(by = ['Stratum'])\n",
    "    \n",
    "    #Equation 11\n",
    "    Nh = ByStratum.Nh.median()\n",
    "    Xest = (Nh * ByStratum.Class2.mean()).sum()\n",
    "    \n",
    "    #Equation 9\n",
    "    Yest = (Nh * ByStratum.Class1.mean()).sum()\n",
    "    R = Yest / Xest\n",
    "\n",
    "    # Equation 10\n",
    "    nh = ByStratum.Class1.count()\n",
    "    meanyh = ByStratum.Class1.mean()\n",
    "    meanxh = ByStratum.Class2.mean()\n",
    "    vary = ByStratum.Class1.var(ddof=1)\n",
    "    varx = ByStratum.Class2.var(ddof=1)\n",
    "    covarxy = (ByStratum.XY.sum() - nh * meanyh * meanxh) / (nh - 1)\n",
    "    StrataVar = Nh**2 * (1 - nh / Nh) * (vary + R**2 * varx - 2 * R * covarxy) / nh\n",
    "    StrataVarSum = StrataVar.sum() / Xest / Xest\n",
    "    SE = np.sqrt(StrataVarSum) * 100\n",
    "    \n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Estimate</th>        <th class=\"col_heading level0 col1\" >% from target class</th>        <th class=\"col_heading level0 col2\" >SE</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row0_col0\" class=\"data row0 col0\" >Type3</td>\n",
       "                        <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row0_col1\" class=\"data row0 col1\" >31.92</td>\n",
       "                        <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row0_col2\" class=\"data row0 col2\" >2.79</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row1_col0\" class=\"data row1 col0\" >Type2</td>\n",
       "                        <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row1_col1\" class=\"data row1 col1\" >49.15</td>\n",
       "                        <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row1_col2\" class=\"data row1 col2\" >2.98</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row2_col0\" class=\"data row2 col0\" >Type0</td>\n",
       "                        <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row2_col1\" class=\"data row2 col1\" >0.00</td>\n",
       "                        <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row3_col0\" class=\"data row3 col0\" >Type1</td>\n",
       "                        <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row3_col1\" class=\"data row3 col1\" >18.92</td>\n",
       "                        <td id=\"T_37dbab38_2de7_11ec_a8be_d0946613b163row3_col2\" class=\"data row3 col2\" >2.33</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bffa2ce400>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of use: estimate % of Types 0-3 from the overall area of the target class (Reference>0).\n",
    "\n",
    "functions = [estimate_class_percent, estimate_class_percent_SE]\n",
    "names = ['% from target class','SE']\n",
    "results=pd.DataFrame()\n",
    "datacopy=pd.DataFrame()\n",
    "\n",
    "for classtype in data['RefType'].unique():\n",
    "    datacopy = data.copy()\n",
    "    #A new Class1 column, where reference values are set to zero if class type is different from the current class type\n",
    "    datacopy['Class1']=np.where(datacopy['RefType'] == classtype, datacopy['Reference'], 0)\n",
    "    \n",
    "    #Set Class2 equal to Reference (total area of target class)\n",
    "    datacopy['Class2']=datacopy['Reference']\n",
    "    \n",
    "    values={}\n",
    "    values = {nm:[fn(datacopy)] for fn, nm in zip(functions,names)}\n",
    "    values[\"Estimate\"]=classtype\n",
    "    values_pd = pd.DataFrame(values).set_index(\"Estimate\")\n",
    "    results = pd.concat([values_pd, results])\n",
    "\n",
    "results=results.reset_index()\n",
    "\n",
    "results.style.hide_index().format({name: '{:.2f}' for name in names})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
